{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajdeepd/sk-samples/blob/main/colab/01_colab_basic_loading_the_kernel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H0hmKGCLaLw"
      },
      "source": [
        "# Basic Loading of the Kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SXuCYPMLaLz"
      },
      "source": [
        "To run the notebooks we recommend using Poetry and starting a shell with a virtual environment\n",
        "prepared to use SK.\n",
        "\n",
        "See [DEV_SETUP.md](../../python/DEV_SETUP.md) for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Lu9X8tF1LaLz"
      },
      "outputs": [],
      "source": [
        "!python -m pip install semantic-kernel==0.3.15.dev0 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.2"
      ],
      "metadata": {
        "id": "2j8ajJfLLtrc",
        "outputId": "c88df0d4-fbe6-4732-e4db-11d5a5ffd0f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.24.2 in /usr/local/lib/python3.10/dist-packages (1.24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DH8NXXfOLaL0"
      },
      "outputs": [],
      "source": [
        "import semantic_kernel as sk\n",
        "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfFSRSCULaL0"
      },
      "source": [
        "You can instantiate the kernel in a few ways, depending on your use case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OCEPBunDLaL0"
      },
      "outputs": [],
      "source": [
        "# Simple instance\n",
        "kernel_1 = sk.Kernel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0blkr3AELaL1"
      },
      "outputs": [],
      "source": [
        "# Instance with a custom logger\n",
        "my_logger = sk.NullLogger()\n",
        "kernel_2 = sk.Kernel(log=my_logger)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQPHAcdhLaL1"
      },
      "source": [
        "When using the kernel for AI requests, the kernel needs some settings like URL and credentials to the AI models.\n",
        "\n",
        "The SDK currently supports OpenAI and Azure OpenAI, other services will be added over time.\n",
        "\n",
        "If you need an Azure OpenAI key, go [here](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/quickstart?pivots=rest-api)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tP38-UHQLaL1",
        "outputId": "f15e1a5f-e990-4c31-a54e-06e33ff270b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<semantic_kernel.kernel.Kernel at 0x7b8346ac6980>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "kernel = sk.Kernel()\n",
        "\n",
        "kernel.add_chat_service(                      # We are adding a text service\n",
        "    \"Azure_curie\",                            # The alias we can use in prompt templates' config.json\n",
        "    AzureChatCompletion(\n",
        "        \"my-finetuned-Curie\",                 # Azure OpenAI *Deployment name*\n",
        "        \"https://contoso.openai.azure.com/\",  # Azure OpenAI *Endpoint*\n",
        "        \"...your Azure OpenAI Key...\"         # Azure OpenAI *Key*\n",
        "    )\n",
        ")\n",
        "\n",
        "kernel.add_chat_service(                      # We are adding a text service\n",
        "    \"OpenAI_chat_gpt\",                        # The alias we can use in prompt templates' config.json\n",
        "    OpenAIChatCompletion(\n",
        "        \"gpt-3.5-turbo\",                      # OpenAI Model Name\n",
        "        \"...your OpenAI API Key...\",          # OpenAI API key\n",
        "        \"...your OpenAI Org ID...\"            # *optional* OpenAI Organization ID\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hpe8hJnLaL1"
      },
      "source": [
        "When working with multiple services and multiple models, the **first service** defined\n",
        "is also the \"**default**\" used in these scenarios:\n",
        "\n",
        "* a prompt configuration doesn't specify which AI service to use\n",
        "* a prompt configuration requires a service unknown to the kernel\n",
        "\n",
        "The default can be set and changed programmatically:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VWht7oG6LaL2",
        "outputId": "f6140aa1-856b-4204-b883-2fc29d48ad3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<semantic_kernel.kernel.Kernel at 0x7b8346ac6980>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "kernel.set_default_text_completion_service(\"Azure_curie\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXAPAVGeLaL2"
      },
      "source": [
        "Great, now that you're familiar with setting up the Semantic Kernel, let's see [how we can use it to run prompts](02-running-prompts-from-file.ipynb)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "polyglot_notebook": {
      "kernelInfo": {
        "items": [
          {
            "aliases": [
              "frontend"
            ],
            "name": "vscode"
          }
        ]
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}