{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajdeepd/sk-samples/blob/main/colab/03-colab-semantic-function-inline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c93ac5b",
      "metadata": {
        "id": "3c93ac5b"
      },
      "source": [
        "# Running Semantic Functions Inline on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebcabb91",
      "metadata": {
        "id": "ebcabb91"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "40201641",
      "metadata": {
        "id": "40201641"
      },
      "source": [
        "The [previous notebook](./02-running-prompts-from-file.ipynb)\n",
        "showed how to define a semantic function using a prompt template stored on a file.\n",
        "\n",
        "In this notebook, we'll show how to use the Semantic Kernel to define functions inline with your python code. This can be useful in a few scenarios:\n",
        "\n",
        "* Dynamically generating the prompt using complex rules at runtime\n",
        "* Writing prompts by editing Python code instead of TXT files.\n",
        "* Easily creating demos, like this document\n",
        "\n",
        "Prompt templates are defined using the SK template language, which allows to reference variables and functions. Read [this doc](https://aka.ms/sk/howto/configurefunction) to learn more about the design decisions for prompt templating.\n",
        "\n",
        "For now we'll use only the `{{$input}}` variable, and see more complex templates later.\n",
        "\n",
        "Almost all semantic function prompts have a reference to `{{$input}}`, which is the default way\n",
        "a user can import content from the context variables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d90b0c13",
      "metadata": {
        "id": "d90b0c13"
      },
      "source": [
        "Prepare a semantic kernel instance first, loading also the AI service settings defined in the [Setup notebook](00-getting-started.ipynb):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1da651d4",
      "metadata": {
        "id": "1da651d4",
        "outputId": "6a080796-c6ee-4783-e9fb-78c36b1e1ae5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting semantic-kernel==0.3.15.dev0\n",
            "  Downloading semantic_kernel-0.3.15.dev0-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.7/200.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0.0,>=23.1.0 (from semantic-kernel==0.3.15.dev0)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting motor<4.0.0,>=3.3.1 (from semantic-kernel==0.3.15.dev0)\n",
            "  Downloading motor-3.3.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<2.0.0,>=1.24.2 (from semantic-kernel==0.3.15.dev0)\n",
            "  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai<0.29,>=0.27 (from semantic-kernel==0.3.15.dev0)\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openapi_core<0.19.0,>=0.18.0 (from semantic-kernel==0.3.15.dev0)\n",
            "  Downloading openapi_core-0.18.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.4/82.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prance<24.0.0.0,>=23.6.21.0 (from semantic-kernel==0.3.15.dev0)\n",
            "  Downloading prance-23.6.21.0-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from semantic-kernel==0.3.15.dev0) (1.10.13)\n",
            "Collecting python-dotenv==1.0.0 (from semantic-kernel==0.3.15.dev0)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: regex<2024.0.0,>=2023.6.3 in /usr/local/lib/python3.10/dist-packages (from semantic-kernel==0.3.15.dev0) (2023.6.3)\n",
            "Collecting pymongo<5,>=4.5 (from motor<4.0.0,>=3.3.1->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (3.9.1)\n",
            "Collecting asgiref<4.0.0,>=3.6.0 (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
            "Collecting isodate (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (4.19.2)\n",
            "Collecting jsonschema-spec<0.3.0,>=0.2.3 (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading jsonschema_spec-0.2.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (10.1.0)\n",
            "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading openapi_schema_validator-0.6.2-py3-none-any.whl (8.8 kB)\n",
            "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading openapi_spec_validator-0.7.1-py3-none-any.whl (38 kB)\n",
            "Collecting parse (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading parse-1.20.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: werkzeug in /usr/local/lib/python3.10/dist-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (3.0.1)\n",
            "Requirement already satisfied: chardet>=3.0 in /usr/local/lib/python3.10/dist-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.3.15.dev0) (5.2.0)\n",
            "Collecting ruamel.yaml>=0.17.10 (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading ruamel.yaml-0.18.5-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six~=1.15 in /usr/local/lib/python3.10/dist-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.3.15.dev0) (1.16.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.3.15.dev0) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2->semantic-kernel==0.3.15.dev0) (4.5.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (0.13.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema-spec<0.3.0,>=0.2.3->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (6.0.1)\n",
            "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-spec<0.3.0,>=0.2.3->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading pathable-0.4.3-py3-none-any.whl (9.6 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading referencing-0.30.2-py3-none-any.whl (25 kB)\n",
            "Collecting rfc3339-validator (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading jsonschema_path-0.3.2-py3-none-any.whl (14 kB)\n",
            "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading lazy_object_proxy-1.9.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo<5,>=4.5->motor<4.0.0,>=3.3.1->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (2023.11.17)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.10->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.29,>=0.27->semantic-kernel==0.3.15.dev0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0) (2.1.3)\n",
            "INFO: pip is looking at multiple versions of jsonschema-specifications to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.3.15.dev0)\n",
            "  Downloading jsonschema_specifications-2023.11.2-py3-none-any.whl (17 kB)\n",
            "  Downloading jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: parse, ruamel.yaml.clib, rfc3339-validator, referencing, python-dotenv, pathable, numpy, lazy-object-proxy, isodate, dnspython, asgiref, aiofiles, ruamel.yaml, pymongo, jsonschema-specifications, jsonschema-spec, jsonschema-path, prance, openai, motor, openapi-schema-validator, openapi-spec-validator, openapi_core, semantic-kernel\n",
            "  Attempting uninstall: referencing\n",
            "    Found existing installation: referencing 0.31.1\n",
            "    Uninstalling referencing-0.31.1:\n",
            "      Successfully uninstalled referencing-0.31.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: jsonschema-specifications\n",
            "    Found existing installation: jsonschema-specifications 2023.11.1\n",
            "    Uninstalling jsonschema-specifications-2023.11.1:\n",
            "      Successfully uninstalled jsonschema-specifications-2023.11.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 asgiref-3.7.2 dnspython-2.4.2 isodate-0.6.1 jsonschema-path-0.3.2 jsonschema-spec-0.2.4 jsonschema-specifications-2023.7.1 lazy-object-proxy-1.9.0 motor-3.3.2 numpy-1.26.2 openai-0.28.1 openapi-schema-validator-0.6.2 openapi-spec-validator-0.7.1 openapi_core-0.18.2 parse-1.20.0 pathable-0.4.3 prance-23.6.21.0 pymongo-4.6.1 python-dotenv-1.0.0 referencing-0.30.2 rfc3339-validator-0.1.4 ruamel.yaml-0.18.5 ruamel.yaml.clib-0.2.8 semantic-kernel-0.3.15.dev0\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install semantic-kernel==0.3.15.dev0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.2"
      ],
      "metadata": {
        "id": "9JIMJV1FW9hV",
        "outputId": "0f787787-ecd8-4d40-9540-97c42c35bc38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "id": "9JIMJV1FW9hV",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.2\n",
            "  Downloading numpy-1.24.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.2\n",
            "    Uninstalling numpy-1.26.2:\n",
            "      Successfully uninstalled numpy-1.26.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "8CMWjoDMXgEA"
      },
      "id": "8CMWjoDMXgEA",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3712b7c3",
      "metadata": {
        "id": "3712b7c3"
      },
      "outputs": [],
      "source": [
        "import semantic_kernel as sk\n",
        "from semantic_kernel.connectors.ai.open_ai import AzureTextCompletion, OpenAITextCompletion\n",
        "\n",
        "kernel = sk.Kernel()\n",
        "\n",
        "useAzureOpenAI = False\n",
        "\n",
        "# Configure AI service used by the kernel\n",
        "if useAzureOpenAI:\n",
        "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
        "    kernel.add_text_completion_service(\"dv\", AzureTextCompletion(deployment, endpoint, api_key))\n",
        "else:\n",
        "    #api_key, org_id = sk.openai_settings_from_dot_env()\n",
        "    api_key, org_id  = OPENAI_API_KEY, \"\"\n",
        "    kernel.add_text_completion_service(\"dv\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "589733c5",
      "metadata": {
        "id": "589733c5"
      },
      "source": [
        "Let's use a prompt to create a semantic function used to summarize content, allowing for some creativity and a sufficient number of tokens.\n",
        "\n",
        "The function will take in input the text to summarize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ae29c207",
      "metadata": {
        "id": "ae29c207"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"{{$input}}\n",
        "Summarize the content above in 20 words\n",
        "\"\"\"\n",
        "\n",
        "summarize = kernel.create_semantic_function(prompt, max_tokens=2000, temperature=0.2, top_p=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f26b90c4",
      "metadata": {
        "id": "f26b90c4"
      },
      "source": [
        "Set up some content to summarize, here's an extract about Demo, an ancient Greek poet, taken from Wikipedia (https://en.wikipedia.org/wiki/Demo_(ancient_Greek_poet)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "314557fb",
      "metadata": {
        "id": "314557fb"
      },
      "outputs": [],
      "source": [
        "input_text = \"\"\"\n",
        "Demo (ancient Greek poet)\n",
        "From Wikipedia, the free encyclopedia\n",
        "Demo or Damo (Greek: Δεμώ, Δαμώ; fl. c. AD 200) was a Greek woman of the Roman period, known for a single epigram, engraved upon the Colossus of Memnon, which bears her name. She speaks of herself therein as a lyric poetess dedicated to the Muses, but nothing is known of her life.[1]\n",
        "Identity\n",
        "Demo was evidently Greek, as her name, a traditional epithet of Demeter, signifies. The name was relatively common in the Hellenistic world, in Egypt and elsewhere, and she cannot be further identified. The date of her visit to the Colossus of Memnon cannot be established with certainty, but internal evidence on the left leg suggests her poem was inscribed there at some point in or after AD 196.[2]\n",
        "Epigram\n",
        "There are a number of graffiti inscriptions on the Colossus of Memnon. Following three epigrams by Julia Balbilla, a fourth epigram, in elegiac couplets, entitled and presumably authored by \"Demo\" or \"Damo\" (the Greek inscription is difficult to read), is a dedication to the Muses.[2] The poem is traditionally published with the works of Balbilla, though the internal evidence suggests a different author.[1]\n",
        "In the poem, Demo explains that Memnon has shown her special respect. In return, Demo offers the gift for poetry, as a gift to the hero. At the end of this epigram, she addresses Memnon, highlighting his divine status by recalling his strength and holiness.[2]\n",
        "Demo, like Julia Balbilla, writes in the artificial and poetic Aeolic dialect. The language indicates she was knowledgeable in Homeric poetry—'bearing a pleasant gift', for example, alludes to the use of that phrase throughout the Iliad and Odyssey.[a][2]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf0f2330",
      "metadata": {
        "id": "bf0f2330"
      },
      "source": [
        "...and run the summary function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7b0e3b0c",
      "metadata": {
        "id": "7b0e3b0c",
        "outputId": "dd978ec8-c9c4-4d00-bf58-9d12030abd5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demo was a Greek poetess of the Roman period, known for an epigram inscribed on the Colossus of Memnon. She wrote a poem dedicated to the Muses in the Aeolic dialect, alluding to Homeric poetry.\n"
          ]
        }
      ],
      "source": [
        "# If needed, async is available too: summary = await summarize.invoke_async(input_text)\n",
        "summary = summarize(input_text)\n",
        "\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c2c1262",
      "metadata": {
        "id": "1c2c1262"
      },
      "source": [
        "# Using ChatCompletion for Semantic Skills"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29b59b28",
      "metadata": {
        "id": "29b59b28"
      },
      "source": [
        "You can also use chat completion models (like `gpt-35-turbo` and `gpt4`) for creating skills. Normally you would have to tweak the API to accommodate for a system and user role, but SK abstracts that away for you by using `kernel.add_chat_service` and `AzureChatCompletion` or `OpenAIChatCompletion`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4777f447",
      "metadata": {
        "id": "4777f447"
      },
      "source": [
        "Here's one more example of how to write an inline Semantic Function that gives a TLDR for a piece of text using a ChatCompletion model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c5886aeb",
      "metadata": {
        "id": "c5886aeb"
      },
      "outputs": [],
      "source": [
        "import semantic_kernel as sk\n",
        "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
        "\n",
        "kernel = sk.Kernel()\n",
        "\n",
        "useAzureOpenAI = False\n",
        "\n",
        "# Configure AI service used by the kernel\n",
        "if useAzureOpenAI:\n",
        "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
        "    kernel.add_chat_service(\n",
        "        \"chat_completion\",\n",
        "        AzureChatCompletion(deployment, endpoint, api_key),\n",
        "    )\n",
        "else:\n",
        "    #api_key, org_id = sk.openai_settings_from_dot_env()\n",
        "    api_key, org_id  = OPENAI_API_KEY, \"\"\n",
        "    kernel.add_chat_service(\n",
        "        \"chat-gpt\", OpenAIChatCompletion(\"gpt-4\", api_key, org_id)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ea8128c8",
      "metadata": {
        "id": "ea8128c8",
        "outputId": "dbaebc98-35c1-4604-e13b-c6b5b6e7f0e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: Robots can't harm or disobey humans.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sk_prompt = \"\"\"\n",
        "{{$input}}\n",
        "\n",
        "Give me the TLDR in 5 words or less.\n",
        "\"\"\"\n",
        "\n",
        "text = \"\"\"\n",
        "    1) A robot may not injure a human being or, through inaction,\n",
        "    allow a human being to come to harm.\n",
        "\n",
        "    2) A robot must obey orders given it by human beings except where\n",
        "    such orders would conflict with the First Law.\n",
        "\n",
        "    3) A robot must protect its own existence as long as such protection\n",
        "    does not conflict with the First or Second Law.\n",
        "\"\"\"\n",
        "\n",
        "tldr_function = kernel.create_semantic_function(sk_prompt, max_tokens=200, temperature=0, top_p=0.5)\n",
        "\n",
        "summary = tldr_function(text)\n",
        "\n",
        "print(f\"Output: {summary}\") # Output: Robots must not harm humans."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}